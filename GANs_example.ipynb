{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtI4dn5l8tQxEQ18EE9CeP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itforankit/GenerativeAI/blob/main/GANs_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nuOobCR9teAF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAN -> Generative Adversarial Network\n",
        "\n",
        "GAN -> Generate new data set based on the traiing data set and new dataset look slike training dataset on which the model ois trained\n",
        "\n",
        "\n",
        "Human faces ----> generate faces which looks like human faces\n",
        "\n",
        "GAN\n",
        "\n",
        "1. Generator [unsupevised] : take random input (noise) and generate samples (image,text,audio) generate real looking sample which are indistinguishable form the training data.\n",
        "\n",
        "  Input: take random input(noisa) -> latent dim 100 -> sample form the normal distribution\n",
        "\n",
        "  Ouput: neuorns in output layer of generator ? 784 -> 28X28\n",
        "\n",
        "  Generator learns by reviewing the gfeedback from the discriminator [good job -> loss fucntion is small] -> backward propogation to update the weights of generator such that the loss funsctions of the discruminator is maximized\n",
        "\n",
        "2. Discriminator[superised]: distinguish between the real and fake data\n",
        "trained on real and fake data [generated images generated by generator]\n",
        "\n",
        "NN\n",
        "\n",
        "Neuorns -> o/p of discriminator -> 1 Neuron\n",
        "\n",
        "I/P of discriiminator  ->image(dim of the image) ex: 28X28=784\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x3oZM4c9vU1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the generator model\n",
        "def build_generator(latent_dim):\n",
        "  generator = keras.Sequential([\n",
        "      layers.Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "      layers.Dense(784, activation='sigmoid'),\n",
        "      layers.Reshape((28,28))\n",
        "  ])\n",
        "  return generator\n",
        "\n",
        "#define the Discriminator model\n",
        "def build_discriminator(input_shape):\n",
        "  discriminator = keras.Sequential([\n",
        "      layers.Flatten(input_shape=input_shape),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      #layers.Droupout(0.5),\n",
        "      layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  return discriminator\n",
        "\n",
        "#combine Generator and Discriminator in to GAN model\n",
        "def build_gan(generator, discriminator):\n",
        "  discriminator.trainable =False\n",
        "  gan=keras.Sequential([\n",
        "      generator,\n",
        "      discriminator\n",
        "  ])\n",
        "  return gan"
      ],
      "metadata": {
        "id": "BxcS2jFdz6Yo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "#x_train = x_train.reshape((-1, 28, 28))"
      ],
      "metadata": {
        "id": "POZXaJyiz655"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the parameters\n",
        "latent_dim =100\n",
        "input_shape =(28,28)\n",
        "epochs =range(10000)\n",
        "batch_size=128\n",
        "\n",
        "#build and compile the models\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator(input_shape)\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "gan=build_gan(generator, discriminator)\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "sEW9m2DVz6-S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do these steps iteratively\n",
        "\n",
        "fake images --> generator(128 fake images) label -> 0 (fake images)\n",
        "\n",
        "real images --> x_train(60,000 -> 128 real images) label -> 1 (real images)[128]\n",
        "\n",
        "fake + real images -> 256 images (labelled data set (faked/real))\n",
        "\n",
        "train our discriminator --> 256 images\n",
        "\n",
        "sample 100 points from normal distribution  --> inout to generator  --> 256 iamges\n",
        "\n",
        "mislabelled y --> set to 1 --> 256  ---> real images\n",
        "\n",
        "freeze the weights disriminator ( the weight will not be learned)\n",
        "\n",
        "train gan (gen + disc) --> supervised --> input random noise --> output (fake not fake) mislabelled 7=y"
      ],
      "metadata": {
        "id": "BEVieRUZ7oze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#training loop\n",
        "for epoch in epochs:\n",
        "  #smaple random noise for generator inout\n",
        "  noise = np.random.normal(0,1,(batch_size, latent_dim))\n",
        "  #generate fake images from noise\n",
        "  generated_images = generator.predict(noise) #128 batch_size\n",
        "\n",
        "  #sample real images\n",
        "  real_images = x_train[np.random.randint(0,x_train.shape[0],batch_size)] # 128 real images\n",
        "\n",
        "  #concatenate real and generated images for discriminator training\n",
        "  x_combined = np.concatenate([real_images,generated_images])\n",
        "\n",
        "  #labels for real(1) and generated images(0)\n",
        "  y_combined = np.concatenate([np.ones((batch_size,1)), np.zeros((batch_size,1))])\n",
        "\n",
        "  #add noise to labels for smoother training\n",
        "  #y_combined += 0.05 * np.random.random(y_combined.shape)\n",
        "\n",
        "  #train discriminator\n",
        "  discriminator.trainable =True\n",
        "  d_loss = discriminator.train_on_batch(x_combined, y_combined) # weights are updating\n",
        "\n",
        "  #train generator\n",
        "  noise = np.random.normal(0,1,(batch_size, latent_dim))\n",
        "  y_mislabeled = np.ones((batch_size,1)) # internally making the fake images as real\n",
        "  discriminator.trainable = False\n",
        "  g_loss = gan.train_on_batch(noise, y_mislabeled)\n",
        "\n",
        "  #print progress\n",
        "  if epoch%100==0:\n",
        "    print(f\"Epoch: {epoch}, Discriminator loss: {d_loss[0]}, Disicriiminator Accuracy: {100 * d_loss[1]:.2f}%, Generstor loss: {g_loss}\")\n",
        "  #plot generated images at ertain intervals\n",
        "  if epoch%1000==0:\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(25):\n",
        "      plt.subplot(5,5,i+1)\n",
        "      plt.imshow(generated_images[i], cmap='gray')\n",
        "      plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "S2iCvbDdz7B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFjKjn4Z7oJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c9K4qCFh7oNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHOZkeG67oQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}